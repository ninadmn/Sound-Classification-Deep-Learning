{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjXdf5kpzJ3Q",
        "colab_type": "text"
      },
      "source": [
        "Import Inception V3 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo54lItU93l0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U7ZYxlkzQDJ",
        "colab_type": "text"
      },
      "source": [
        "We will be using all the layers in the model except the last fully connected layer as it is specific to 'imagenet'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dPL0fxo-W-e",
        "colab_type": "code",
        "outputId": "d1e082dd-a5e5-488b-ac37-3da2648a500f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "pre_trained_model = InceptionV3(input_shape= (250,400,3), include_top=False, weights='imagenet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm5WERgOzW7S",
        "colab_type": "text"
      },
      "source": [
        "Setting all the layers as non trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opvzP4MRPiRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable=False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V0eYDC70sGa",
        "colab_type": "text"
      },
      "source": [
        "We use categorical_crossentropy as the loss metric as we have 10 target classes. Our optimizer is Adam with a learning rate of 0.0001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxVyrtFQQGdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "x = pre_trained_model.output\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(1024,activation = 'relu')(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(10, activation='softmax')(x)\n",
        "model = Model(pre_trained_model.input,x)\n",
        "model.compile(optimizer = Adam(lr=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ22cCUKdEWG",
        "colab_type": "code",
        "outputId": "00811f39-c751-41b1-8937-6717c55ec06a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 149, 149, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 149, 149, 32) 96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 149, 149, 32) 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 147, 147, 32) 9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 147, 147, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 147, 147, 32) 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 147, 147, 64) 18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 147, 147, 64) 192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 147, 147, 64) 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 73, 73, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 73, 73, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 71, 71, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 71, 71, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 71, 71, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 35, 35, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 35, 35, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 35, 35, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 35, 35, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 35, 35, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 35, 35, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 35, 35, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 35, 35, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 35, 35, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 35, 35, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 35, 35, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 35, 35, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 35, 35, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 35, 35, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 35, 35, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 35, 35, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 35, 35, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 35, 35, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 35, 35, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 35, 35, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 35, 35, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 35, 35, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 35, 35, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 35, 35, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 35, 35, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 35, 35, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 35, 35, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 35, 35, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 35, 35, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 35, 35, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 35, 35, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 35, 35, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 35, 35, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 35, 35, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 35, 35, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 35, 35, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 35, 35, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 35, 35, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 35, 35, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 35, 35, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 35, 35, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 35, 35, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 35, 35, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 35, 35, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 35, 35, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 35, 35, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 35, 35, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 35, 35, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 35, 35, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 35, 35, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 35, 35, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 35, 35, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 35, 35, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 35, 35, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 35, 35, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 35, 35, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 17, 17, 96)   82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 17, 17, 384)  1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 17, 17, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 17, 17, 384)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 17, 17, 96)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 17, 17, 128)  384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 17, 17, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 17, 17, 128)  114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 17, 17, 128)  114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 17, 17, 128)  114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 17, 17, 128)  114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 17, 17, 128)  384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 17, 17, 128)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 17, 17, 192)  172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 17, 17, 192)  172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 17, 17, 160)  179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 17, 17, 160)  179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 17, 17, 160)  480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 17, 17, 160)  480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 17, 17, 160)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 17, 17, 160)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 17, 17, 160)  179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 17, 17, 160)  179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 17, 17, 160)  480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 17, 17, 160)  480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 17, 17, 160)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 17, 17, 160)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 17, 17, 192)  215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 17, 17, 192)  215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 17, 17, 192)  576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 17, 17, 192)  576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 17, 17, 192)  576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 17, 17, 192)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 17, 17, 192)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 17, 17, 192)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 17, 17, 160)  480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 17, 17, 160)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 17, 17, 160)  179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 17, 17, 160)  480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 17, 17, 160)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 17, 17, 160)  179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 17, 17, 160)  480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 17, 17, 160)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 17, 17, 160)  179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 17, 17, 160)  179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 17, 17, 192)  215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 17, 17, 192)  576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 17, 17, 192)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 17, 17, 192)  258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 17, 17, 192)  576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 17, 17, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 17, 17, 192)  258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 17, 17, 192)  576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 17, 17, 192)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 17, 17, 192)  258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 17, 17, 192)  258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 17, 17, 192)  576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 17, 17, 192)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 17, 17, 192)  258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 17, 17, 192)  258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 17, 17, 192)  576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 17, 17, 192)  576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 17, 17, 192)  576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 17, 17, 192)  576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 17, 17, 192)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 17, 17, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 17, 17, 192)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 17, 17, 192)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 17, 17, 192)  576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 17, 17, 192)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 17, 17, 192)  258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 17, 17, 192)  576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 17, 17, 192)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 17, 17, 192)  258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 17, 17, 192)  576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 17, 17, 192)  576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 17, 17, 192)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 17, 17, 192)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 8, 8, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 8, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 8, 8, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 8, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 8, 8, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 131072)       0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1024)         134218752   flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 10)           10250       dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 156,031,786\n",
            "Trainable params: 134,229,002\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOIJ_L4X2F9g",
        "colab_type": "text"
      },
      "source": [
        "**Rescaling Images Using ImageDataGenerator**\n",
        "\n",
        "Using ImageDataGenerator class, we will read images from the source folder and feed them to the network. One generator for training and other for validating. Normalization helps in processing of data in neural nets hance we will process the images by normalizing the pixel values to be [0,1] After rescaling the images, and using Image Augmentation, we flow them in batches of 20 using train_datagen and test_datagen.\n",
        "\n",
        "\n",
        "We also perform **image augmentation** where we change the images a bit by rotating them, squashing them, etc.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPYG0M_KdLGH",
        "colab_type": "code",
        "outputId": "76d53259-02ba-4e4c-9b56-02f02cd97a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrMu1S0b2RPD",
        "colab_type": "text"
      },
      "source": [
        "We have 6980 training images with 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvkEuJy2jkci",
        "colab_type": "code",
        "outputId": "6e1e388a-4243-4622-f1b3-459f30e8bbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory('/content/drive/My Drive/train2', batch_size = 20, class_mode='categorical', target_size=(299,299))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6980 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XqYppAEv2S3",
        "colab_type": "code",
        "outputId": "77b7a664-f41d-4d66-d028-721c67470463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_generator.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H6QYfWL2YFb",
        "colab_type": "text"
      },
      "source": [
        "We have 1740 testing images with 10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJbHFD8t48pX",
        "colab_type": "code",
        "outputId": "aa2dd5ba-58c5-42a6-8eff-cbe410d78e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = test_datagen.flow_from_directory('/content/drive/My Drive/test2', batch_size = 20, class_mode='categorical', target_size=(299,299))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1740 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFpu6p7EjEZU",
        "colab_type": "code",
        "outputId": "62eefe65-53f7-49dc-cb3b-0665c2264a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(validation_generator.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DVZfjgH5YoR",
        "colab_type": "code",
        "outputId": "7d3b78cd-1d70-475d-85d7-2a31c7b8950f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=349,  \n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=87,  \n",
        "      verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "349/349 [==============================] - 143s 411ms/step - loss: 1.4295 - accuracy: 0.6234 - val_loss: 0.6425 - val_accuracy: 0.7845\n",
            "Epoch 2/100\n",
            "349/349 [==============================] - 147s 420ms/step - loss: 0.7728 - accuracy: 0.7415 - val_loss: 0.5716 - val_accuracy: 0.7994\n",
            "Epoch 3/100\n",
            "349/349 [==============================] - 148s 425ms/step - loss: 0.6844 - accuracy: 0.7686 - val_loss: 0.4972 - val_accuracy: 0.8310\n",
            "Epoch 4/100\n",
            "349/349 [==============================] - 150s 430ms/step - loss: 0.5884 - accuracy: 0.8059 - val_loss: 0.4610 - val_accuracy: 0.8471\n",
            "Epoch 5/100\n",
            "349/349 [==============================] - 150s 430ms/step - loss: 0.5542 - accuracy: 0.8146 - val_loss: 0.4809 - val_accuracy: 0.8316\n",
            "Epoch 6/100\n",
            "349/349 [==============================] - 152s 435ms/step - loss: 0.5209 - accuracy: 0.8238 - val_loss: 0.4044 - val_accuracy: 0.8569\n",
            "Epoch 7/100\n",
            "349/349 [==============================] - 151s 434ms/step - loss: 0.4649 - accuracy: 0.8427 - val_loss: 0.3680 - val_accuracy: 0.8753\n",
            "Epoch 8/100\n",
            "349/349 [==============================] - 152s 436ms/step - loss: 0.4635 - accuracy: 0.8421 - val_loss: 0.3880 - val_accuracy: 0.8655\n",
            "Epoch 9/100\n",
            "349/349 [==============================] - 150s 429ms/step - loss: 0.4133 - accuracy: 0.8609 - val_loss: 0.4085 - val_accuracy: 0.8718\n",
            "Epoch 10/100\n",
            "349/349 [==============================] - 150s 430ms/step - loss: 0.4092 - accuracy: 0.8610 - val_loss: 0.3819 - val_accuracy: 0.8701\n",
            "Epoch 11/100\n",
            "349/349 [==============================] - 155s 443ms/step - loss: 0.3908 - accuracy: 0.8679 - val_loss: 0.3472 - val_accuracy: 0.8851\n",
            "Epoch 12/100\n",
            "349/349 [==============================] - 158s 452ms/step - loss: 0.3760 - accuracy: 0.8658 - val_loss: 0.3463 - val_accuracy: 0.8891\n",
            "Epoch 13/100\n",
            "349/349 [==============================] - 151s 433ms/step - loss: 0.3511 - accuracy: 0.8725 - val_loss: 0.3629 - val_accuracy: 0.8810\n",
            "Epoch 14/100\n",
            "349/349 [==============================] - 151s 432ms/step - loss: 0.3517 - accuracy: 0.8781 - val_loss: 0.3577 - val_accuracy: 0.8793\n",
            "Epoch 15/100\n",
            "349/349 [==============================] - 145s 417ms/step - loss: 0.3500 - accuracy: 0.8828 - val_loss: 0.3398 - val_accuracy: 0.8879\n",
            "Epoch 16/100\n",
            "349/349 [==============================] - 146s 419ms/step - loss: 0.3176 - accuracy: 0.8911 - val_loss: 0.3204 - val_accuracy: 0.8977\n",
            "Epoch 17/100\n",
            "349/349 [==============================] - 142s 408ms/step - loss: 0.3092 - accuracy: 0.8944 - val_loss: 0.3204 - val_accuracy: 0.8954\n",
            "Epoch 18/100\n",
            "349/349 [==============================] - 143s 408ms/step - loss: 0.3219 - accuracy: 0.8900 - val_loss: 0.3203 - val_accuracy: 0.9017\n",
            "Epoch 19/100\n",
            "349/349 [==============================] - 145s 417ms/step - loss: 0.3067 - accuracy: 0.8915 - val_loss: 0.3742 - val_accuracy: 0.8770\n",
            "Epoch 20/100\n",
            "349/349 [==============================] - 141s 405ms/step - loss: 0.2974 - accuracy: 0.8964 - val_loss: 0.3303 - val_accuracy: 0.8960\n",
            "Epoch 21/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.2854 - accuracy: 0.8996 - val_loss: 0.2923 - val_accuracy: 0.9086\n",
            "Epoch 22/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.2976 - accuracy: 0.8973 - val_loss: 0.3077 - val_accuracy: 0.9057\n",
            "Epoch 23/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.2621 - accuracy: 0.9085 - val_loss: 0.3463 - val_accuracy: 0.8920\n",
            "Epoch 24/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.2526 - accuracy: 0.9128 - val_loss: 0.3294 - val_accuracy: 0.9057\n",
            "Epoch 25/100\n",
            "349/349 [==============================] - 142s 408ms/step - loss: 0.2655 - accuracy: 0.9067 - val_loss: 0.3362 - val_accuracy: 0.9069\n",
            "Epoch 26/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.2493 - accuracy: 0.9146 - val_loss: 0.3090 - val_accuracy: 0.9046\n",
            "Epoch 27/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.2573 - accuracy: 0.9113 - val_loss: 0.3324 - val_accuracy: 0.9006\n",
            "Epoch 28/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.2312 - accuracy: 0.9193 - val_loss: 0.3304 - val_accuracy: 0.9029\n",
            "Epoch 29/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.2359 - accuracy: 0.9185 - val_loss: 0.3076 - val_accuracy: 0.9069\n",
            "Epoch 30/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.2247 - accuracy: 0.9245 - val_loss: 0.2731 - val_accuracy: 0.9172\n",
            "Epoch 31/100\n",
            "349/349 [==============================] - 140s 403ms/step - loss: 0.2235 - accuracy: 0.9198 - val_loss: 0.3379 - val_accuracy: 0.9023\n",
            "Epoch 32/100\n",
            "349/349 [==============================] - 139s 399ms/step - loss: 0.2132 - accuracy: 0.9209 - val_loss: 0.2710 - val_accuracy: 0.9080\n",
            "Epoch 33/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.2162 - accuracy: 0.9226 - val_loss: 0.3248 - val_accuracy: 0.9132\n",
            "Epoch 34/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.2135 - accuracy: 0.9262 - val_loss: 0.2985 - val_accuracy: 0.9075\n",
            "Epoch 35/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1977 - accuracy: 0.9272 - val_loss: 0.2816 - val_accuracy: 0.9126\n",
            "Epoch 36/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.2032 - accuracy: 0.9314 - val_loss: 0.2580 - val_accuracy: 0.9184\n",
            "Epoch 37/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1995 - accuracy: 0.9327 - val_loss: 0.2913 - val_accuracy: 0.9144\n",
            "Epoch 38/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.2075 - accuracy: 0.9251 - val_loss: 0.3278 - val_accuracy: 0.9052\n",
            "Epoch 39/100\n",
            "349/349 [==============================] - 139s 399ms/step - loss: 0.2200 - accuracy: 0.9234 - val_loss: 0.3336 - val_accuracy: 0.9063\n",
            "Epoch 40/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.2018 - accuracy: 0.9292 - val_loss: 0.2700 - val_accuracy: 0.9236\n",
            "Epoch 41/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.2013 - accuracy: 0.9321 - val_loss: 0.3415 - val_accuracy: 0.8966\n",
            "Epoch 42/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1951 - accuracy: 0.9340 - val_loss: 0.2902 - val_accuracy: 0.9092\n",
            "Epoch 43/100\n",
            "349/349 [==============================] - 139s 399ms/step - loss: 0.1694 - accuracy: 0.9374 - val_loss: 0.3095 - val_accuracy: 0.9172\n",
            "Epoch 44/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.2012 - accuracy: 0.9285 - val_loss: 0.2961 - val_accuracy: 0.9172\n",
            "Epoch 45/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1813 - accuracy: 0.9365 - val_loss: 0.3371 - val_accuracy: 0.9121\n",
            "Epoch 46/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1854 - accuracy: 0.9375 - val_loss: 0.2784 - val_accuracy: 0.9092\n",
            "Epoch 47/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1887 - accuracy: 0.9330 - val_loss: 0.3859 - val_accuracy: 0.9063\n",
            "Epoch 48/100\n",
            "349/349 [==============================] - 139s 400ms/step - loss: 0.1717 - accuracy: 0.9375 - val_loss: 0.3369 - val_accuracy: 0.9103\n",
            "Epoch 49/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1769 - accuracy: 0.9421 - val_loss: 0.3319 - val_accuracy: 0.9109\n",
            "Epoch 50/100\n",
            "349/349 [==============================] - 139s 399ms/step - loss: 0.1696 - accuracy: 0.9390 - val_loss: 0.2575 - val_accuracy: 0.9259\n",
            "Epoch 51/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1621 - accuracy: 0.9447 - val_loss: 0.2961 - val_accuracy: 0.9218\n",
            "Epoch 52/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1678 - accuracy: 0.9421 - val_loss: 0.2695 - val_accuracy: 0.9195\n",
            "Epoch 53/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1459 - accuracy: 0.9467 - val_loss: 0.3151 - val_accuracy: 0.9230\n",
            "Epoch 54/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.1608 - accuracy: 0.9424 - val_loss: 0.3020 - val_accuracy: 0.9195\n",
            "Epoch 55/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1604 - accuracy: 0.9441 - val_loss: 0.3118 - val_accuracy: 0.9213\n",
            "Epoch 56/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.1567 - accuracy: 0.9457 - val_loss: 0.3092 - val_accuracy: 0.9236\n",
            "Epoch 57/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1733 - accuracy: 0.9414 - val_loss: 0.3239 - val_accuracy: 0.9172\n",
            "Epoch 58/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.1540 - accuracy: 0.9474 - val_loss: 0.3151 - val_accuracy: 0.9138\n",
            "Epoch 59/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1412 - accuracy: 0.9489 - val_loss: 0.2871 - val_accuracy: 0.9167\n",
            "Epoch 60/100\n",
            "349/349 [==============================] - 141s 404ms/step - loss: 0.1673 - accuracy: 0.9426 - val_loss: 0.3038 - val_accuracy: 0.9178\n",
            "Epoch 61/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1597 - accuracy: 0.9450 - val_loss: 0.2654 - val_accuracy: 0.9241\n",
            "Epoch 62/100\n",
            "349/349 [==============================] - 140s 403ms/step - loss: 0.1382 - accuracy: 0.9504 - val_loss: 0.3436 - val_accuracy: 0.9218\n",
            "Epoch 63/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.1403 - accuracy: 0.9506 - val_loss: 0.3344 - val_accuracy: 0.9167\n",
            "Epoch 64/100\n",
            "349/349 [==============================] - 141s 405ms/step - loss: 0.1371 - accuracy: 0.9537 - val_loss: 0.3085 - val_accuracy: 0.9276\n",
            "Epoch 65/100\n",
            "349/349 [==============================] - 143s 408ms/step - loss: 0.1365 - accuracy: 0.9514 - val_loss: 0.3443 - val_accuracy: 0.9063\n",
            "Epoch 66/100\n",
            "349/349 [==============================] - 141s 403ms/step - loss: 0.1419 - accuracy: 0.9501 - val_loss: 0.3155 - val_accuracy: 0.9230\n",
            "Epoch 67/100\n",
            "349/349 [==============================] - 141s 403ms/step - loss: 0.1469 - accuracy: 0.9494 - val_loss: 0.3035 - val_accuracy: 0.9236\n",
            "Epoch 68/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1350 - accuracy: 0.9554 - val_loss: 0.3060 - val_accuracy: 0.9253\n",
            "Epoch 69/100\n",
            "349/349 [==============================] - 140s 403ms/step - loss: 0.1391 - accuracy: 0.9499 - val_loss: 0.2945 - val_accuracy: 0.9224\n",
            "Epoch 70/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1320 - accuracy: 0.9530 - val_loss: 0.3425 - val_accuracy: 0.9236\n",
            "Epoch 71/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.1421 - accuracy: 0.9491 - val_loss: 0.2918 - val_accuracy: 0.9195\n",
            "Epoch 72/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1452 - accuracy: 0.9490 - val_loss: 0.3017 - val_accuracy: 0.9230\n",
            "Epoch 73/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1369 - accuracy: 0.9517 - val_loss: 0.2805 - val_accuracy: 0.9218\n",
            "Epoch 74/100\n",
            "349/349 [==============================] - 139s 399ms/step - loss: 0.1345 - accuracy: 0.9562 - val_loss: 0.3082 - val_accuracy: 0.9241\n",
            "Epoch 75/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1305 - accuracy: 0.9547 - val_loss: 0.3175 - val_accuracy: 0.9184\n",
            "Epoch 76/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1256 - accuracy: 0.9569 - val_loss: 0.3056 - val_accuracy: 0.9241\n",
            "Epoch 77/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1373 - accuracy: 0.9523 - val_loss: 0.3643 - val_accuracy: 0.9052\n",
            "Epoch 78/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.1537 - accuracy: 0.9468 - val_loss: 0.2980 - val_accuracy: 0.9190\n",
            "Epoch 79/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1390 - accuracy: 0.9532 - val_loss: 0.2896 - val_accuracy: 0.9264\n",
            "Epoch 80/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1303 - accuracy: 0.9587 - val_loss: 0.3143 - val_accuracy: 0.9218\n",
            "Epoch 81/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1197 - accuracy: 0.9553 - val_loss: 0.3175 - val_accuracy: 0.9213\n",
            "Epoch 82/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1286 - accuracy: 0.9547 - val_loss: 0.2867 - val_accuracy: 0.9310\n",
            "Epoch 83/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1421 - accuracy: 0.9511 - val_loss: 0.3137 - val_accuracy: 0.9241\n",
            "Epoch 84/100\n",
            "349/349 [==============================] - 141s 405ms/step - loss: 0.1253 - accuracy: 0.9540 - val_loss: 0.3295 - val_accuracy: 0.9132\n",
            "Epoch 85/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1173 - accuracy: 0.9576 - val_loss: 0.3191 - val_accuracy: 0.9270\n",
            "Epoch 86/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1294 - accuracy: 0.9540 - val_loss: 0.3211 - val_accuracy: 0.9184\n",
            "Epoch 87/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1236 - accuracy: 0.9560 - val_loss: 0.3119 - val_accuracy: 0.9259\n",
            "Epoch 88/100\n",
            "349/349 [==============================] - 139s 399ms/step - loss: 0.1212 - accuracy: 0.9567 - val_loss: 0.3027 - val_accuracy: 0.9264\n",
            "Epoch 89/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1303 - accuracy: 0.9540 - val_loss: 0.3014 - val_accuracy: 0.9224\n",
            "Epoch 90/100\n",
            "349/349 [==============================] - 141s 403ms/step - loss: 0.1171 - accuracy: 0.9573 - val_loss: 0.3106 - val_accuracy: 0.9276\n",
            "Epoch 91/100\n",
            "349/349 [==============================] - 141s 404ms/step - loss: 0.1141 - accuracy: 0.9622 - val_loss: 0.2838 - val_accuracy: 0.9270\n",
            "Epoch 92/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1253 - accuracy: 0.9583 - val_loss: 0.3459 - val_accuracy: 0.9230\n",
            "Epoch 93/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1217 - accuracy: 0.9583 - val_loss: 0.3064 - val_accuracy: 0.9264\n",
            "Epoch 94/100\n",
            "349/349 [==============================] - 140s 400ms/step - loss: 0.1016 - accuracy: 0.9666 - val_loss: 0.3601 - val_accuracy: 0.9172\n",
            "Epoch 95/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1156 - accuracy: 0.9610 - val_loss: 0.3168 - val_accuracy: 0.9201\n",
            "Epoch 96/100\n",
            "349/349 [==============================] - 140s 401ms/step - loss: 0.1170 - accuracy: 0.9580 - val_loss: 0.3315 - val_accuracy: 0.9282\n",
            "Epoch 97/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.1073 - accuracy: 0.9600 - val_loss: 0.3216 - val_accuracy: 0.9247\n",
            "Epoch 98/100\n",
            "349/349 [==============================] - 141s 404ms/step - loss: 0.1247 - accuracy: 0.9569 - val_loss: 0.3276 - val_accuracy: 0.9195\n",
            "Epoch 99/100\n",
            "349/349 [==============================] - 140s 402ms/step - loss: 0.1175 - accuracy: 0.9580 - val_loss: 0.3167 - val_accuracy: 0.9178\n",
            "Epoch 100/100\n",
            "349/349 [==============================] - 141s 403ms/step - loss: 0.1239 - accuracy: 0.9580 - val_loss: 0.2634 - val_accuracy: 0.9310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMYyDonFVL-K",
        "colab_type": "code",
        "outputId": "12a7fe10-2f94-4a68-dc8d-522ee3b1e888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(train_generator, verbose=1)\n",
        "print(\"Training Accuracy: \", score[1])\n",
        "\n",
        "score = model.evaluate(validation_generator, verbose=1)\n",
        "print(\"Testing Accuracy: \", score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  35222/Unknown - 13379s 380ms/step - loss: 0.0372 - accuracy: 0.9872"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "662rXlWF_PUi",
        "colab_type": "text"
      },
      "source": [
        "**Define a Callback class that stops training once accuracy reaches 95%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1PXBwR938T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_acc')>0.95):\n",
        "      print(\"\\nReached 95.00% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icP19cKE_tVZ",
        "colab_type": "text"
      },
      "source": [
        "**Using the layers including and above mixed 7**, here we do not use all the layers in the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LNu3a8F4dcO",
        "colab_type": "code",
        "outputId": "1560a4c8-45c4-42f8-ba4e-c05c6e60bcae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7') #Only use layers including and above 'mixed7'\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 13, 23, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9Jt0iEt4y9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#last_layer = pre_trained_model.get_layer('mixed7')\n",
        "#print('last layer output shape: ', last_layer.output_shape)\n",
        "#last_output = last_layer.output\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.4\n",
        "x = layers.Dropout(0.4)(x)                  \n",
        "# Add a final softmax layer for classification\n",
        "x = layers.Dense  (10, activation='softmax')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.0001), \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gODe-Q8z5WKo",
        "colab_type": "code",
        "outputId": "bb70ba8a-1d81-433a-d073-93be6f7084dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# The validation data will not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/My Drive/train2',\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'categorical', \n",
        "                                                    target_size = (250, 400))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( '/content/drive/My Drive/test2',\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'categorical', \n",
        "                                                          target_size = (250, 400))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6980 images belonging to 10 classes.\n",
            "Found 1740 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYNR5k0gAo2A",
        "colab_type": "text"
      },
      "source": [
        "To calculate steps_per_epoch  we used Toal training images // batch_size\n",
        "\n",
        "To calculate validation_steps  we used Toal test images // batch_size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mY6nQKZ5sX4",
        "colab_type": "code",
        "outputId": "9558a20a-fe31-4d9a-ca0a-f095db13c370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 349,\n",
        "            epochs = 100,\n",
        "            validation_steps = 87,\n",
        "            verbose = 1,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-986cfd30909d>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "349/349 [==============================] - 9644s 28s/step - loss: 1.1419 - acc: 0.6160 - val_loss: 0.7738 - val_acc: 0.7517\n",
            "Epoch 2/100\n",
            "349/349 [==============================] - 282s 807ms/step - loss: 0.6159 - acc: 0.7983 - val_loss: 0.4381 - val_acc: 0.8500\n",
            "Epoch 3/100\n",
            "349/349 [==============================] - 281s 806ms/step - loss: 0.5107 - acc: 0.8332 - val_loss: 0.5779 - val_acc: 0.8092\n",
            "Epoch 4/100\n",
            "349/349 [==============================] - 281s 804ms/step - loss: 0.4009 - acc: 0.8668 - val_loss: 0.4141 - val_acc: 0.8799\n",
            "Epoch 5/100\n",
            "349/349 [==============================] - 281s 804ms/step - loss: 0.3497 - acc: 0.8812 - val_loss: 0.3762 - val_acc: 0.8753\n",
            "Epoch 6/100\n",
            "349/349 [==============================] - 282s 807ms/step - loss: 0.3158 - acc: 0.8976 - val_loss: 0.3292 - val_acc: 0.8920\n",
            "Epoch 7/100\n",
            "349/349 [==============================] - 282s 809ms/step - loss: 0.3005 - acc: 0.8970 - val_loss: 0.7074 - val_acc: 0.8437\n",
            "Epoch 8/100\n",
            "349/349 [==============================] - 282s 808ms/step - loss: 0.2622 - acc: 0.9155 - val_loss: 0.2874 - val_acc: 0.9167\n",
            "Epoch 9/100\n",
            "349/349 [==============================] - 281s 806ms/step - loss: 0.2410 - acc: 0.9195 - val_loss: 0.2331 - val_acc: 0.9374\n",
            "Epoch 10/100\n",
            "349/349 [==============================] - 280s 803ms/step - loss: 0.2286 - acc: 0.9258 - val_loss: 0.2546 - val_acc: 0.9374\n",
            "Epoch 11/100\n",
            "349/349 [==============================] - 282s 808ms/step - loss: 0.2025 - acc: 0.9332 - val_loss: 0.3589 - val_acc: 0.9132\n",
            "Epoch 12/100\n",
            "349/349 [==============================] - 286s 819ms/step - loss: 0.1956 - acc: 0.9368 - val_loss: 0.2331 - val_acc: 0.9408\n",
            "Epoch 13/100\n",
            "349/349 [==============================] - 284s 813ms/step - loss: 0.1836 - acc: 0.9383 - val_loss: 0.2493 - val_acc: 0.9356\n",
            "Epoch 14/100\n",
            "349/349 [==============================] - 281s 805ms/step - loss: 0.1753 - acc: 0.9456 - val_loss: 0.3437 - val_acc: 0.9264\n",
            "Epoch 15/100\n",
            "349/349 [==============================] - 282s 809ms/step - loss: 0.1782 - acc: 0.9440 - val_loss: 0.2952 - val_acc: 0.9213\n",
            "Epoch 16/100\n",
            "349/349 [==============================] - 283s 810ms/step - loss: 0.1634 - acc: 0.9447 - val_loss: 0.2736 - val_acc: 0.9374\n",
            "Epoch 17/100\n",
            "349/349 [==============================] - 282s 809ms/step - loss: 0.1485 - acc: 0.9497 - val_loss: 0.2899 - val_acc: 0.9316\n",
            "Epoch 18/100\n",
            "349/349 [==============================] - 282s 809ms/step - loss: 0.1440 - acc: 0.9532 - val_loss: 0.2545 - val_acc: 0.9333\n",
            "Epoch 19/100\n",
            "349/349 [==============================] - ETA: 0s - loss: 0.1371 - acc: 0.9553\n",
            "Reached 95.00% accuracy so cancelling training!\n",
            "349/349 [==============================] - 281s 805ms/step - loss: 0.1371 - acc: 0.9553 - val_loss: 0.2042 - val_acc: 0.9517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcsuDGHYBU0F",
        "colab_type": "text"
      },
      "source": [
        "**Plot accuracy and Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxVTZO4TzvA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "2b855666-fefe-4313-d1d3-65d55c70ce0f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDzgJSLuDvIS",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Testing Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzPJKupqCT-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f751975c-f8c6-46b8-f1b8-887f21b6e8cb"
      },
      "source": [
        "score = model.evaluate_generator(validation_generator, 1740/20, verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87/87 [==============================] - 15s 176ms/step - loss: 0.2233 - acc: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}